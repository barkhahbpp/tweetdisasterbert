{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barkhahbpp/tweetdisasterbert/blob/main/bert_disaster_tweet_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX9YK996e0Rw"
      },
      "source": [
        "# 1. Installing Dependencies #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3kNBjb_LOsd"
      },
      "source": [
        "Install dependency packages / libraries that support NLP Tweet Disaster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJmyWfKjepgF",
        "outputId": "aeb14c3d-3d11-420f-d211-ff6d7d0ecb54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/6.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/6.5 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ppLIUMGALD2"
      },
      "source": [
        "# 2. Dataset #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1B9c2ZNLgdk"
      },
      "source": [
        "Link Dataset :\n",
        "\n",
        "https://github.com/barkhahbpp/tweetdisasterbert.git\n",
        "\n",
        "Sumber Dataset :\n",
        "\n",
        "https://www.kaggle.com/datasets/vstepanenko/disaster-tweets\n",
        "\n",
        "https://www.kaggle.com/datasets/vbmokin/nlp-with-disaster-tweets-cleaning-data\n",
        "\n",
        "**Data Descripstion**\n",
        "\n",
        "|Field name|Description|\n",
        "|--- |--- |\n",
        "|id\t|A unique identifier for each tweet |\n",
        "|keyword\t|A particular keyword from the tweet |\n",
        "|location\t|The location the tweet was sent from (may be blank) |\n",
        "|text| The text of the tweet|\n",
        "|target| Denotes whether a tweet is about a real disaster (1) or not (0)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VO9BL_9NXXd"
      },
      "source": [
        "## 2.1. Data Loading ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BnnKc8fHLf8n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg8PwoE8ABhB",
        "outputId": "7d7c0c27-5188-4270-adc9-fdb607dd25fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11370 entries, 0 to 11369\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        11370 non-null  int64 \n",
            " 1   keyword   11370 non-null  object\n",
            " 2   location  7952 non-null   object\n",
            " 3   text      11370 non-null  object\n",
            " 4   target    11370 non-null  int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 444.3+ KB\n"
          ]
        }
      ],
      "source": [
        "dataseturl = \"https://raw.githubusercontent.com/barkhahbpp/tweetdisasterbert/main/dataset/tweets.csv\"\n",
        "twdisaster_df = pd.read_csv(dataseturl)\n",
        "twdisaster_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMhkjkKNOzS9"
      },
      "source": [
        "## 2.2. Explanatory Data Analysis ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QSSzq1sBWAur"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "o4fy4QYnO5bE",
        "outputId": "05a8c138-4d7b-4e4a-c375-f1861bf14a0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword        location  \\\n",
              "0   0  ablaze             NaN   \n",
              "1   1  ablaze             NaN   \n",
              "2   2  ablaze   New York City   \n",
              "3   3  ablaze  Morgantown, WV   \n",
              "4   4  ablaze             NaN   \n",
              "\n",
              "                                                text  target  \n",
              "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
              "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
              "2  Arsonist sets cars ablaze at dealership https:...       1  \n",
              "3  Arsonist sets cars ablaze at dealership https:...       1  \n",
              "4  \"Lord Jesus, your love brings freedom and pard...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5774f1e8-db31-4f91-ad4e-98989276a727\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>New York City</td>\n",
              "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Morgantown, WV</td>\n",
              "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5774f1e8-db31-4f91-ad4e-98989276a727')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5774f1e8-db31-4f91-ad4e-98989276a727 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5774f1e8-db31-4f91-ad4e-98989276a727');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8c07490-6d4e-4a2a-92c4-96933b9ca12d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8c07490-6d4e-4a2a-92c4-96933b9ca12d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8c07490-6d4e-4a2a-92c4-96933b9ca12d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "twdisaster_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "gMIpu2_TPG5-",
        "outputId": "965c4c4f-b570-417b-838b-48473424a2e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id                                                           \\\n",
              "         count         mean          std  min      25%     50%      75%   \n",
              "target                                                                    \n",
              "0       9256.0  5631.622191  3247.050923  4.0  2853.75  5635.5  8404.50   \n",
              "1       2114.0  5916.021760  3423.980548  0.0  2714.50  5930.0  9131.75   \n",
              "\n",
              "                 \n",
              "            max  \n",
              "target           \n",
              "0       11368.0  \n",
              "1       11369.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd3b1e0b-9fd4-4859-bf3b-de4db762b5cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9256.0</td>\n",
              "      <td>5631.622191</td>\n",
              "      <td>3247.050923</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2853.75</td>\n",
              "      <td>5635.5</td>\n",
              "      <td>8404.50</td>\n",
              "      <td>11368.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2114.0</td>\n",
              "      <td>5916.021760</td>\n",
              "      <td>3423.980548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2714.50</td>\n",
              "      <td>5930.0</td>\n",
              "      <td>9131.75</td>\n",
              "      <td>11369.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd3b1e0b-9fd4-4859-bf3b-de4db762b5cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd3b1e0b-9fd4-4859-bf3b-de4db762b5cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd3b1e0b-9fd4-4859-bf3b-de4db762b5cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46fd1d62-43be-4688-8ec6-d97775243c20\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46fd1d62-43be-4688-8ec6-d97775243c20')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46fd1d62-43be-4688-8ec6-d97775243c20 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "twdisaster_df.groupby('target').describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9hGcdZkCZWpF"
      },
      "outputs": [],
      "source": [
        "twdisaster = len(twdisaster_df.loc[twdisaster_df['target']==1])\n",
        "twnotdisaster = len(twdisaster_df.loc[twdisaster_df['target']==0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "BhiMdp5mPfwc",
        "outputId": "97976e39-bc86-41f0-91ed-f114ccdd1a67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1700x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prop_disaster = twdisaster / len(twdisaster_df) * 100\n",
        "prop_notdisaster = twnotdisaster / len(twdisaster_df) * 100\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\n",
        "plt.tight_layout()\n",
        "\n",
        "twdisaster_df.groupby('target').count()['id'].plot(kind='pie', ax=axes[0], labels=['Not Disaster ('+'{:.2f}'.format(prop_notdisaster)+')', 'Disaster ('+'{:.2f}'.format(prop_disaster)+')'])\n",
        "sns.countplot(x=twdisaster_df['target'], hue=twdisaster_df['target'], ax=axes[1])\n",
        "\n",
        "axes[0].set_ylabel('')\n",
        "axes[1].set_ylabel('')\n",
        "axes[1].set_xticklabels(['Not Disaster ('+str(twnotdisaster)+')', 'Disaster ('+str(twdisaster)+')'])\n",
        "axes[0].tick_params(axis='x', labelsize=15)\n",
        "axes[0].tick_params(axis='y', labelsize=15)\n",
        "axes[1].tick_params(axis='x', labelsize=15)\n",
        "axes[1].tick_params(axis='y', labelsize=15)\n",
        "\n",
        "axes[0].set_title('Target Distribution in Dataset', fontsize=13)\n",
        "axes[1].set_title('Target Count in Dataset', fontsize=13)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrc25KBsGubh"
      },
      "source": [
        "## 2.3. Addressing Problem Imbalanced Data ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3EGZ5JVUVtM"
      },
      "source": [
        "According to the dataset analytics, we conlude that the data are imbalanced. Non-disaster data are larger than disaster data. We use the downsampling to balance data between disaster and non-disaster. Downsampling is a technique to handle imbalanced data that reduce the number of samples having the bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3s4OKynT6KE",
        "outputId": "9e1de6e7-5df4-4a46-9a31-cd8bbe63b9fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2114, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "disaster_df = twdisaster_df[twdisaster_df['target']==1]\n",
        "disaster_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8kpMqCdGoy_",
        "outputId": "81243622-9ea4-45c5-8e3c-9443c4738fdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9256, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nondisaster_df = twdisaster_df[twdisaster_df['target']==0]\n",
        "nondisaster_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jJPQ7fJGqwr",
        "outputId": "5464c498-3a55-4356-87df-bd7bebac492b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2114, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "downsampled_nondisaster_df = nondisaster_df.sample(disaster_df.shape[0])\n",
        "downsampled_nondisaster_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBdAGM5WHiKk",
        "outputId": "5c868050-3ebf-4042-fd16-cb9e55e486ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4228, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "balanced_df = pd.concat([disaster_df, downsampled_nondisaster_df])\n",
        "balanced_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REnwHz8TI7ry",
        "outputId": "321eaaf8-b3e5-4315-a5ad-5fef46025fa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2114\n",
              "0    2114\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "balanced_df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k-SOFQD9JBlY",
        "outputId": "abb7c40c-cc4d-4a91-ad00-ca51f842229e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id              keyword                       location  \\\n",
              "10162  10162              thunder                       Virginia   \n",
              "4062    4062             detonate                   Florida, USA   \n",
              "1985    1985         bush%20fires                     Austin, TX   \n",
              "9062    9062              screams                Santiago, Chile   \n",
              "9247    9247               sirens     Johannesburg, South Africa   \n",
              "9404    9404            snowstorm                            NaN   \n",
              "1513    1513                 bomb                            NaN   \n",
              "6649    6649             hostages                San Antonio, TX   \n",
              "6364    6364          heat%20wave                            NaN   \n",
              "3268    3268               debris               New Delhi, India   \n",
              "9224    9224              sinking                   Planet Earth   \n",
              "4609    4609           earthquake                          Chile   \n",
              "4041    4041             detonate                Chennai, Bharat   \n",
              "4899    4899             engulfed     Fremont Street, Des Moines   \n",
              "123      123  airplane%20accident                  Virginia, USA   \n",
              "9143    9143             sinkhole                 United Kingdom   \n",
              "1892    1892              burning  Penultimate page of The Lorax   \n",
              "9623    9623       suicide%20bomb           Rawalpindi, Pakistan   \n",
              "5494    5494                 fear                     Edmond, OK   \n",
              "6011    6011       forest%20fires                          JAPAN   \n",
              "\n",
              "                                                    text  target  \n",
              "10162  Literally just heard the loudest thunder, it s...       1  \n",
              "4062   So you would have to detonate 6,150,000,000 (y...       0  \n",
              "1985   Jeff Bezos says Amazon is donating $690,000 to...       0  \n",
              "9062   Who the hell screams “get away for me” while c...       0  \n",
              "9247   Emergency my ass, he should have sirens if tha...       0  \n",
              "9404   Torn utility wire from snowstorm, or a Termina...       1  \n",
              "1513   BREAKING: Bomb in Van of NJ Kosher Market Terr...       1  \n",
              "6649   MASTER SYSTEM MONDAY: CHOPLIFTER In 1986 Sega ...       1  \n",
              "6364   #LatestNews #Trending A January heat wave engu...       1  \n",
              "3268   NEWS: On 13 jan two Avalanches have hit in J&a...       1  \n",
              "9224   That’s why the club is sinking deeper every se...       0  \n",
              "4609   Temblor: mb 4.5 SOUTHEAST OF EASTER ISLAND: Ma...       1  \n",
              "4041   . flight makes an emergency landing in Kolkata...       1  \n",
              "4899   DMRegister: Over the course of the 12-hour sta...       1  \n",
              "123    So Iranian radars cannot tell the difference b...       1  \n",
              "9143   China: At least six dead as huge sinkhole swal...       1  \n",
              "1892   the world is watching, and heating and burning...       0  \n",
              "9623   Last 3 weeks main 3 bomb &amp; suicide attacks...       1  \n",
              "5494   If you are afraid people are taking advantage ...       0  \n",
              "6011   Some regions of the world at risk of forest fi...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b6bbbb6-a055-4ef3-b6ee-0d5020e7efbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10162</th>\n",
              "      <td>10162</td>\n",
              "      <td>thunder</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>Literally just heard the loudest thunder, it s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4062</th>\n",
              "      <td>4062</td>\n",
              "      <td>detonate</td>\n",
              "      <td>Florida, USA</td>\n",
              "      <td>So you would have to detonate 6,150,000,000 (y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>1985</td>\n",
              "      <td>bush%20fires</td>\n",
              "      <td>Austin, TX</td>\n",
              "      <td>Jeff Bezos says Amazon is donating $690,000 to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9062</th>\n",
              "      <td>9062</td>\n",
              "      <td>screams</td>\n",
              "      <td>Santiago, Chile</td>\n",
              "      <td>Who the hell screams “get away for me” while c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9247</th>\n",
              "      <td>9247</td>\n",
              "      <td>sirens</td>\n",
              "      <td>Johannesburg, South Africa</td>\n",
              "      <td>Emergency my ass, he should have sirens if tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9404</th>\n",
              "      <td>9404</td>\n",
              "      <td>snowstorm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Torn utility wire from snowstorm, or a Termina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>1513</td>\n",
              "      <td>bomb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BREAKING: Bomb in Van of NJ Kosher Market Terr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6649</th>\n",
              "      <td>6649</td>\n",
              "      <td>hostages</td>\n",
              "      <td>San Antonio, TX</td>\n",
              "      <td>MASTER SYSTEM MONDAY: CHOPLIFTER In 1986 Sega ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6364</th>\n",
              "      <td>6364</td>\n",
              "      <td>heat%20wave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#LatestNews #Trending A January heat wave engu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>3268</td>\n",
              "      <td>debris</td>\n",
              "      <td>New Delhi, India</td>\n",
              "      <td>NEWS: On 13 jan two Avalanches have hit in J&amp;a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9224</th>\n",
              "      <td>9224</td>\n",
              "      <td>sinking</td>\n",
              "      <td>Planet Earth</td>\n",
              "      <td>That’s why the club is sinking deeper every se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>4609</td>\n",
              "      <td>earthquake</td>\n",
              "      <td>Chile</td>\n",
              "      <td>Temblor: mb 4.5 SOUTHEAST OF EASTER ISLAND: Ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4041</th>\n",
              "      <td>4041</td>\n",
              "      <td>detonate</td>\n",
              "      <td>Chennai, Bharat</td>\n",
              "      <td>. flight makes an emergency landing in Kolkata...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4899</th>\n",
              "      <td>4899</td>\n",
              "      <td>engulfed</td>\n",
              "      <td>Fremont Street, Des Moines</td>\n",
              "      <td>DMRegister: Over the course of the 12-hour sta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>airplane%20accident</td>\n",
              "      <td>Virginia, USA</td>\n",
              "      <td>So Iranian radars cannot tell the difference b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9143</th>\n",
              "      <td>9143</td>\n",
              "      <td>sinkhole</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>China: At least six dead as huge sinkhole swal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>1892</td>\n",
              "      <td>burning</td>\n",
              "      <td>Penultimate page of The Lorax</td>\n",
              "      <td>the world is watching, and heating and burning...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9623</th>\n",
              "      <td>9623</td>\n",
              "      <td>suicide%20bomb</td>\n",
              "      <td>Rawalpindi, Pakistan</td>\n",
              "      <td>Last 3 weeks main 3 bomb &amp;amp; suicide attacks...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5494</th>\n",
              "      <td>5494</td>\n",
              "      <td>fear</td>\n",
              "      <td>Edmond, OK</td>\n",
              "      <td>If you are afraid people are taking advantage ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6011</th>\n",
              "      <td>6011</td>\n",
              "      <td>forest%20fires</td>\n",
              "      <td>JAPAN</td>\n",
              "      <td>Some regions of the world at risk of forest fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b6bbbb6-a055-4ef3-b6ee-0d5020e7efbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b6bbbb6-a055-4ef3-b6ee-0d5020e7efbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b6bbbb6-a055-4ef3-b6ee-0d5020e7efbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92a20d09-77f3-4af9-b8b6-4e8e1913d05e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92a20d09-77f3-4af9-b8b6-4e8e1913d05e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92a20d09-77f3-4af9-b8b6-4e8e1913d05e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "balanced_df.sample(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7SfbeIhKjZy"
      },
      "source": [
        "# 3. Data Preprocessing#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hr8DHLlb9yx"
      },
      "source": [
        "## 3.1. Splitting Train and Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6DvVdj1Zuc1"
      },
      "source": [
        "Model will split dataset into training and test. We stratify data sample in which each class have an equal number of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FiRztQkhJRIK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(balanced_df['text'], balanced_df['target'], stratify=balanced_df['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUb1JDb_XP1O",
        "outputId": "df253a8e-9572-4378-c1f9-2189e5304c85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1586\n",
              "1    1585\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF8VrsAfZhmp",
        "outputId": "033208cf-a0a4-4cc0-fa4d-8dfa00ed5ff9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    529\n",
              "0    528\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBRhnYtlcXKP"
      },
      "source": [
        "# 4. Developing BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KLUwyfacjgf"
      },
      "source": [
        "In this part, we employ BERT Preprocessing model and Bert Encoder from Tensorflow_hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MSh_EQZbdCoU"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SipjOc43c3LN"
      },
      "source": [
        "## 4.1. Sentence Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ADg03_ftZk6N"
      },
      "outputs": [],
      "source": [
        "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "# encoder_url = 'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4'\n",
        "encoder_url = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/2'\n",
        "\n",
        "bert_preprocess = hub.KerasLayer(preprocess_url)\n",
        "bert_encoder = hub.KerasLayer(encoder_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RFV24HtOUm0k"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embeding(sentences):\n",
        "  preproc_text = bert_preprocess(sentences)\n",
        "  return bert_encoder(preproc_text)['pooled_output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeBYEHl6awyH",
        "outputId": "8143b201-e027-4c61-b9ce-1cdcc56075bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.2286333 , -0.3659288 , -0.4097298 , ..., -0.06806725,\n",
              "        -0.3766694 , -0.17801426],\n",
              "       [-0.36531276, -0.08574688, -0.99161583, ...,  0.0127456 ,\n",
              "        -0.26177835, -0.12990755]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# get_sentence_embeding(\n",
        "#     [\"Are you speaking about the atrocities and annihilation of Christians across the Middle East committed by Muslims daily?\",\n",
        "#      \"Piscataway land // DC,this is an unfathomable number. I lived through a large earthquake and we slept under the table for one terrible night…\"\n",
        "#     ])\n",
        "\n",
        "get_sentence_embeding(\n",
        "    [\"Are you speaking about the atrocities and annihilation of Christians across the Middle East committed by Muslims daily?\",\n",
        "     \"Piscataway land // DC,this is an unfathomable number. I lived through a large earthquake and we slept under the table for one terrible night…\"\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tD0NX27p82R"
      },
      "source": [
        "## 4.2. Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HGEZdGVfqEr2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# BERT Model\n",
        "text_input_layer = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input_layer)\n",
        "bert_output = bert_encoder(preprocessed_text)\n",
        "\n",
        "#Neural Network Layers\n",
        "layer = tf.keras.layers.Dropout(0.1, name=\"dropout\")(bert_output['pooled_output'])\n",
        "layer = tf.keras.layers.Dense(8, activation='relu', name='hidden1')(layer)\n",
        "layer = tf.keras.layers.Dense(5, activation='relu', name='hidden2')(layer)\n",
        "layer = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(layer)\n",
        "\n",
        "#Final Model\n",
        "model = tf.keras.Model(inputs=[text_input_layer], outputs=[layer])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BCldWWnuWpb",
        "outputId": "b61fa559-7c02-4a5f-b2bd-3f02b3e9befc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)    {'input_mask': (None, 128)   0         ['text[0][0]']                \n",
            "                             , 'input_type_ids': (None,                                           \n",
            "                              128),                                                               \n",
            "                              'input_word_ids': (None,                                            \n",
            "                             128)}                                                                \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)  {'pooled_output': (None, 5   3506841   ['keras_layer[0][0]',         \n",
            "                             12),                         7          'keras_layer[0][1]',         \n",
            "                              'default': (None, 512),                'keras_layer[0][2]']         \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 512),                                                         \n",
            "                              (None, 128, 512),                                                   \n",
            "                              (None, 128, 512),                                                   \n",
            "                              (None, 128, 512),                                                   \n",
            "                              (None, 128, 512),                                                   \n",
            "                              (None, 128, 512)],                                                  \n",
            "                              'sequence_output': (None,                                           \n",
            "                              128, 512)}                                                          \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 512)                  0         ['keras_layer_1[0][7]']       \n",
            "                                                                                                  \n",
            " hidden1 (Dense)             (None, 8)                    4104      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " hidden2 (Dense)             (None, 5)                    45        ['hidden1[0][0]']             \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 1)                    6         ['hidden2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 35072572 (133.79 MB)\n",
            "Trainable params: 4155 (16.23 KB)\n",
            "Non-trainable params: 35068417 (133.78 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtUHqJB5u4Kk",
        "outputId": "849ed2a0-4268-4f18-b6e2-dd4e09d181d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3171"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2tU-J3bCzfDl"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSGxGCWTzx5G"
      },
      "source": [
        "# 5. Train The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0OnVvWCz93a"
      },
      "source": [
        "## 5.1. Fit Model ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeWRNehRz9gF",
        "outputId": "c16d00fe-6266-4502-9185-644f387296de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "100/100 [==============================] - 22s 133ms/step - loss: 0.6737 - accuracy: 0.5926 - precision: 0.5988 - recall: 0.5603\n",
            "Epoch 2/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.6119 - accuracy: 0.6824 - precision: 0.6704 - recall: 0.7174\n",
            "Epoch 3/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.5585 - accuracy: 0.7244 - precision: 0.7212 - recall: 0.7312\n",
            "Epoch 4/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.5245 - accuracy: 0.7439 - precision: 0.7495 - recall: 0.7325\n",
            "Epoch 5/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.5073 - accuracy: 0.7610 - precision: 0.7625 - recall: 0.7577\n",
            "Epoch 6/600\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.4961 - accuracy: 0.7685 - precision: 0.7729 - recall: 0.7603\n",
            "Epoch 7/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4802 - accuracy: 0.7774 - precision: 0.7801 - recall: 0.7722\n",
            "Epoch 8/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4729 - accuracy: 0.7767 - precision: 0.7774 - recall: 0.7754\n",
            "Epoch 9/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4730 - accuracy: 0.7805 - precision: 0.7859 - recall: 0.7710\n",
            "Epoch 10/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4675 - accuracy: 0.7868 - precision: 0.7912 - recall: 0.7792\n",
            "Epoch 11/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4614 - accuracy: 0.7934 - precision: 0.7966 - recall: 0.7880\n",
            "Epoch 12/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4594 - accuracy: 0.7900 - precision: 0.7990 - recall: 0.7748\n",
            "Epoch 13/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4571 - accuracy: 0.7928 - precision: 0.7940 - recall: 0.7905\n",
            "Epoch 14/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4563 - accuracy: 0.7893 - precision: 0.7945 - recall: 0.7804\n",
            "Epoch 15/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4478 - accuracy: 0.7941 - precision: 0.8006 - recall: 0.7830\n",
            "Epoch 16/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4504 - accuracy: 0.7881 - precision: 0.7895 - recall: 0.7855\n",
            "Epoch 17/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4525 - accuracy: 0.7969 - precision: 0.7999 - recall: 0.7918\n",
            "Epoch 18/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4478 - accuracy: 0.7969 - precision: 0.8045 - recall: 0.7842\n",
            "Epoch 19/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4476 - accuracy: 0.8035 - precision: 0.8079 - recall: 0.7962\n",
            "Epoch 20/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4407 - accuracy: 0.8026 - precision: 0.8072 - recall: 0.7950\n",
            "Epoch 21/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4472 - accuracy: 0.7931 - precision: 0.8010 - recall: 0.7798\n",
            "Epoch 22/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.4394 - accuracy: 0.8029 - precision: 0.8061 - recall: 0.7975\n",
            "Epoch 23/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4414 - accuracy: 0.8016 - precision: 0.8045 - recall: 0.7968\n",
            "Epoch 24/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4394 - accuracy: 0.7997 - precision: 0.8037 - recall: 0.7931\n",
            "Epoch 25/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4362 - accuracy: 0.8038 - precision: 0.8073 - recall: 0.7981\n",
            "Epoch 26/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4383 - accuracy: 0.8004 - precision: 0.8083 - recall: 0.7874\n",
            "Epoch 27/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4388 - accuracy: 0.8026 - precision: 0.8048 - recall: 0.7987\n",
            "Epoch 28/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4389 - accuracy: 0.8001 - precision: 0.8023 - recall: 0.7962\n",
            "Epoch 29/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4356 - accuracy: 0.8035 - precision: 0.8079 - recall: 0.7962\n",
            "Epoch 30/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4371 - accuracy: 0.8035 - precision: 0.8068 - recall: 0.7981\n",
            "Epoch 31/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4272 - accuracy: 0.8079 - precision: 0.8120 - recall: 0.8013\n",
            "Epoch 32/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4428 - accuracy: 0.7960 - precision: 0.7999 - recall: 0.7893\n",
            "Epoch 33/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4357 - accuracy: 0.8016 - precision: 0.8041 - recall: 0.7975\n",
            "Epoch 34/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4385 - accuracy: 0.7994 - precision: 0.8055 - recall: 0.7893\n",
            "Epoch 35/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4266 - accuracy: 0.8038 - precision: 0.8057 - recall: 0.8006\n",
            "Epoch 36/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4364 - accuracy: 0.7972 - precision: 0.8054 - recall: 0.7836\n",
            "Epoch 37/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4303 - accuracy: 0.8092 - precision: 0.8133 - recall: 0.8025\n",
            "Epoch 38/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4324 - accuracy: 0.8045 - precision: 0.8143 - recall: 0.7886\n",
            "Epoch 39/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4341 - accuracy: 0.8064 - precision: 0.8075 - recall: 0.8044\n",
            "Epoch 40/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4329 - accuracy: 0.8067 - precision: 0.8111 - recall: 0.7994\n",
            "Epoch 41/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4381 - accuracy: 0.8013 - precision: 0.8127 - recall: 0.7830\n",
            "Epoch 42/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4346 - accuracy: 0.8038 - precision: 0.8053 - recall: 0.8013\n",
            "Epoch 43/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4261 - accuracy: 0.8070 - precision: 0.8125 - recall: 0.7981\n",
            "Epoch 44/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4241 - accuracy: 0.8089 - precision: 0.8124 - recall: 0.8032\n",
            "Epoch 45/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4283 - accuracy: 0.8076 - precision: 0.8147 - recall: 0.7962\n",
            "Epoch 46/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4394 - accuracy: 0.8001 - precision: 0.7963 - recall: 0.8063\n",
            "Epoch 47/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4314 - accuracy: 0.8048 - precision: 0.8084 - recall: 0.7987\n",
            "Epoch 48/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4334 - accuracy: 0.7966 - precision: 0.7997 - recall: 0.7912\n",
            "Epoch 49/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4233 - accuracy: 0.8083 - precision: 0.8133 - recall: 0.8000\n",
            "Epoch 50/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4261 - accuracy: 0.8010 - precision: 0.8093 - recall: 0.7874\n",
            "Epoch 51/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4222 - accuracy: 0.8105 - precision: 0.8162 - recall: 0.8013\n",
            "Epoch 52/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4253 - accuracy: 0.8051 - precision: 0.8097 - recall: 0.7975\n",
            "Epoch 53/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4216 - accuracy: 0.8067 - precision: 0.8140 - recall: 0.7950\n",
            "Epoch 54/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4354 - accuracy: 0.8038 - precision: 0.8007 - recall: 0.8088\n",
            "Epoch 55/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4204 - accuracy: 0.8086 - precision: 0.8091 - recall: 0.8076\n",
            "Epoch 56/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4193 - accuracy: 0.8089 - precision: 0.8116 - recall: 0.8044\n",
            "Epoch 57/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4352 - accuracy: 0.7985 - precision: 0.8017 - recall: 0.7931\n",
            "Epoch 58/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4178 - accuracy: 0.8070 - precision: 0.8117 - recall: 0.7994\n",
            "Epoch 59/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4210 - accuracy: 0.8193 - precision: 0.8248 - recall: 0.8107\n",
            "Epoch 60/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4224 - accuracy: 0.8130 - precision: 0.8159 - recall: 0.8082\n",
            "Epoch 61/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4313 - accuracy: 0.8042 - precision: 0.8094 - recall: 0.7956\n",
            "Epoch 62/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4205 - accuracy: 0.8127 - precision: 0.8186 - recall: 0.8032\n",
            "Epoch 63/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4217 - accuracy: 0.8076 - precision: 0.8127 - recall: 0.7994\n",
            "Epoch 64/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4245 - accuracy: 0.8054 - precision: 0.8036 - recall: 0.8082\n",
            "Epoch 65/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4222 - accuracy: 0.8064 - precision: 0.8118 - recall: 0.7975\n",
            "Epoch 66/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4211 - accuracy: 0.8092 - precision: 0.8157 - recall: 0.7987\n",
            "Epoch 67/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4182 - accuracy: 0.8136 - precision: 0.8206 - recall: 0.8025\n",
            "Epoch 68/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4189 - accuracy: 0.8196 - precision: 0.8220 - recall: 0.8158\n",
            "Epoch 69/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4239 - accuracy: 0.8086 - precision: 0.8103 - recall: 0.8057\n",
            "Epoch 70/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4177 - accuracy: 0.8083 - precision: 0.8090 - recall: 0.8069\n",
            "Epoch 71/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4198 - accuracy: 0.8168 - precision: 0.8226 - recall: 0.8076\n",
            "Epoch 72/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4204 - accuracy: 0.8064 - precision: 0.8098 - recall: 0.8006\n",
            "Epoch 73/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4221 - accuracy: 0.8061 - precision: 0.8162 - recall: 0.7899\n",
            "Epoch 74/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4124 - accuracy: 0.8193 - precision: 0.8256 - recall: 0.8095\n",
            "Epoch 75/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4095 - accuracy: 0.8149 - precision: 0.8211 - recall: 0.8050\n",
            "Epoch 76/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4252 - accuracy: 0.8029 - precision: 0.8113 - recall: 0.7893\n",
            "Epoch 77/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4171 - accuracy: 0.8149 - precision: 0.8146 - recall: 0.8151\n",
            "Epoch 78/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4211 - accuracy: 0.8092 - precision: 0.8121 - recall: 0.8044\n",
            "Epoch 79/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4122 - accuracy: 0.8086 - precision: 0.8111 - recall: 0.8044\n",
            "Epoch 80/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4134 - accuracy: 0.8127 - precision: 0.8142 - recall: 0.8101\n",
            "Epoch 81/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4132 - accuracy: 0.8079 - precision: 0.8132 - recall: 0.7994\n",
            "Epoch 82/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4161 - accuracy: 0.8102 - precision: 0.8185 - recall: 0.7968\n",
            "Epoch 83/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4192 - accuracy: 0.8108 - precision: 0.8139 - recall: 0.8057\n",
            "Epoch 84/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4117 - accuracy: 0.8155 - precision: 0.8173 - recall: 0.8126\n",
            "Epoch 85/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4157 - accuracy: 0.8130 - precision: 0.8155 - recall: 0.8088\n",
            "Epoch 86/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4115 - accuracy: 0.8139 - precision: 0.8224 - recall: 0.8006\n",
            "Epoch 87/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4186 - accuracy: 0.8146 - precision: 0.8173 - recall: 0.8101\n",
            "Epoch 88/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4140 - accuracy: 0.8168 - precision: 0.8206 - recall: 0.8107\n",
            "Epoch 89/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4080 - accuracy: 0.8165 - precision: 0.8176 - recall: 0.8145\n",
            "Epoch 90/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4096 - accuracy: 0.8139 - precision: 0.8167 - recall: 0.8095\n",
            "Epoch 91/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4158 - accuracy: 0.8057 - precision: 0.8080 - recall: 0.8019\n",
            "Epoch 92/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4107 - accuracy: 0.8102 - precision: 0.8125 - recall: 0.8063\n",
            "Epoch 93/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4163 - accuracy: 0.8114 - precision: 0.8145 - recall: 0.8063\n",
            "Epoch 94/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4144 - accuracy: 0.8102 - precision: 0.8141 - recall: 0.8038\n",
            "Epoch 95/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4121 - accuracy: 0.8177 - precision: 0.8161 - recall: 0.8202\n",
            "Epoch 96/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.4100 - accuracy: 0.8149 - precision: 0.8195 - recall: 0.8076\n",
            "Epoch 97/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4126 - accuracy: 0.8146 - precision: 0.8161 - recall: 0.8120\n",
            "Epoch 98/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4123 - accuracy: 0.8165 - precision: 0.8140 - recall: 0.8202\n",
            "Epoch 99/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4177 - accuracy: 0.8108 - precision: 0.8143 - recall: 0.8050\n",
            "Epoch 100/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4130 - accuracy: 0.8079 - precision: 0.8132 - recall: 0.7994\n",
            "Epoch 101/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4112 - accuracy: 0.8143 - precision: 0.8196 - recall: 0.8057\n",
            "Epoch 102/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4133 - accuracy: 0.8168 - precision: 0.8202 - recall: 0.8114\n",
            "Epoch 103/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4070 - accuracy: 0.8127 - precision: 0.8150 - recall: 0.8088\n",
            "Epoch 104/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4147 - accuracy: 0.8117 - precision: 0.8163 - recall: 0.8044\n",
            "Epoch 105/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4082 - accuracy: 0.8174 - precision: 0.8176 - recall: 0.8170\n",
            "Epoch 106/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4044 - accuracy: 0.8212 - precision: 0.8201 - recall: 0.8227\n",
            "Epoch 107/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4090 - accuracy: 0.8124 - precision: 0.8177 - recall: 0.8038\n",
            "Epoch 108/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4052 - accuracy: 0.8146 - precision: 0.8169 - recall: 0.8107\n",
            "Epoch 109/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4059 - accuracy: 0.8206 - precision: 0.8261 - recall: 0.8120\n",
            "Epoch 110/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.4147 - accuracy: 0.8225 - precision: 0.8247 - recall: 0.8189\n",
            "Epoch 111/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4140 - accuracy: 0.8114 - precision: 0.8141 - recall: 0.8069\n",
            "Epoch 112/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4029 - accuracy: 0.8202 - precision: 0.8230 - recall: 0.8158\n",
            "Epoch 113/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4061 - accuracy: 0.8158 - precision: 0.8202 - recall: 0.8088\n",
            "Epoch 114/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4089 - accuracy: 0.8187 - precision: 0.8288 - recall: 0.8032\n",
            "Epoch 115/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4129 - accuracy: 0.8143 - precision: 0.8201 - recall: 0.8050\n",
            "Epoch 116/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4068 - accuracy: 0.8161 - precision: 0.8155 - recall: 0.8170\n",
            "Epoch 117/600\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.4080 - accuracy: 0.8180 - precision: 0.8239 - recall: 0.8088\n",
            "Epoch 118/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3999 - accuracy: 0.8215 - precision: 0.8239 - recall: 0.8177\n",
            "Epoch 119/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4047 - accuracy: 0.8161 - precision: 0.8224 - recall: 0.8063\n",
            "Epoch 120/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4088 - accuracy: 0.8161 - precision: 0.8159 - recall: 0.8164\n",
            "Epoch 121/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4071 - accuracy: 0.8180 - precision: 0.8227 - recall: 0.8107\n",
            "Epoch 122/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4046 - accuracy: 0.8218 - precision: 0.8228 - recall: 0.8202\n",
            "Epoch 123/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3994 - accuracy: 0.8221 - precision: 0.8275 - recall: 0.8139\n",
            "Epoch 124/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4027 - accuracy: 0.8174 - precision: 0.8200 - recall: 0.8132\n",
            "Epoch 125/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4066 - accuracy: 0.8111 - precision: 0.8152 - recall: 0.8044\n",
            "Epoch 126/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3986 - accuracy: 0.8228 - precision: 0.8203 - recall: 0.8265\n",
            "Epoch 127/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4092 - accuracy: 0.8149 - precision: 0.8203 - recall: 0.8063\n",
            "Epoch 128/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4099 - accuracy: 0.8168 - precision: 0.8193 - recall: 0.8126\n",
            "Epoch 129/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4008 - accuracy: 0.8221 - precision: 0.8279 - recall: 0.8132\n",
            "Epoch 130/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4007 - accuracy: 0.8212 - precision: 0.8263 - recall: 0.8132\n",
            "Epoch 131/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3953 - accuracy: 0.8225 - precision: 0.8340 - recall: 0.8050\n",
            "Epoch 132/600\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.3985 - accuracy: 0.8149 - precision: 0.8211 - recall: 0.8050\n",
            "Epoch 133/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4053 - accuracy: 0.8133 - precision: 0.8193 - recall: 0.8038\n",
            "Epoch 134/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3943 - accuracy: 0.8209 - precision: 0.8249 - recall: 0.8145\n",
            "Epoch 135/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3958 - accuracy: 0.8215 - precision: 0.8272 - recall: 0.8126\n",
            "Epoch 136/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.4000 - accuracy: 0.8184 - precision: 0.8257 - recall: 0.8069\n",
            "Epoch 137/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4002 - accuracy: 0.8158 - precision: 0.8215 - recall: 0.8069\n",
            "Epoch 138/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3984 - accuracy: 0.8266 - precision: 0.8282 - recall: 0.8240\n",
            "Epoch 139/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4018 - accuracy: 0.8206 - precision: 0.8286 - recall: 0.8082\n",
            "Epoch 140/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4040 - accuracy: 0.8228 - precision: 0.8273 - recall: 0.8158\n",
            "Epoch 141/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3956 - accuracy: 0.8202 - precision: 0.8214 - recall: 0.8183\n",
            "Epoch 142/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4042 - accuracy: 0.8146 - precision: 0.8161 - recall: 0.8120\n",
            "Epoch 143/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3943 - accuracy: 0.8240 - precision: 0.8277 - recall: 0.8183\n",
            "Epoch 144/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4037 - accuracy: 0.8177 - precision: 0.8201 - recall: 0.8139\n",
            "Epoch 145/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3917 - accuracy: 0.8228 - precision: 0.8294 - recall: 0.8126\n",
            "Epoch 146/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3970 - accuracy: 0.8190 - precision: 0.8259 - recall: 0.8082\n",
            "Epoch 147/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3960 - accuracy: 0.8250 - precision: 0.8293 - recall: 0.8183\n",
            "Epoch 148/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3988 - accuracy: 0.8278 - precision: 0.8311 - recall: 0.8227\n",
            "Epoch 149/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3988 - accuracy: 0.8174 - precision: 0.8176 - recall: 0.8170\n",
            "Epoch 150/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3980 - accuracy: 0.8243 - precision: 0.8299 - recall: 0.8158\n",
            "Epoch 151/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4030 - accuracy: 0.8177 - precision: 0.8255 - recall: 0.8057\n",
            "Epoch 152/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3951 - accuracy: 0.8231 - precision: 0.8188 - recall: 0.8297\n",
            "Epoch 153/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4060 - accuracy: 0.8171 - precision: 0.8252 - recall: 0.8044\n",
            "Epoch 154/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4018 - accuracy: 0.8174 - precision: 0.8288 - recall: 0.8000\n",
            "Epoch 155/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3903 - accuracy: 0.8272 - precision: 0.8322 - recall: 0.8196\n",
            "Epoch 156/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4061 - accuracy: 0.8158 - precision: 0.8182 - recall: 0.8120\n",
            "Epoch 157/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3956 - accuracy: 0.8240 - precision: 0.8277 - recall: 0.8183\n",
            "Epoch 158/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3855 - accuracy: 0.8253 - precision: 0.8294 - recall: 0.8189\n",
            "Epoch 159/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3924 - accuracy: 0.8262 - precision: 0.8268 - recall: 0.8252\n",
            "Epoch 160/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3925 - accuracy: 0.8247 - precision: 0.8304 - recall: 0.8158\n",
            "Epoch 161/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3913 - accuracy: 0.8284 - precision: 0.8296 - recall: 0.8265\n",
            "Epoch 162/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3929 - accuracy: 0.8190 - precision: 0.8189 - recall: 0.8189\n",
            "Epoch 163/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3944 - accuracy: 0.8266 - precision: 0.8315 - recall: 0.8189\n",
            "Epoch 164/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3927 - accuracy: 0.8234 - precision: 0.8233 - recall: 0.8233\n",
            "Epoch 165/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3838 - accuracy: 0.8297 - precision: 0.8339 - recall: 0.8233\n",
            "Epoch 166/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3874 - accuracy: 0.8272 - precision: 0.8309 - recall: 0.8215\n",
            "Epoch 167/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3871 - accuracy: 0.8269 - precision: 0.8338 - recall: 0.8164\n",
            "Epoch 168/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3946 - accuracy: 0.8168 - precision: 0.8177 - recall: 0.8151\n",
            "Epoch 169/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3890 - accuracy: 0.8225 - precision: 0.8247 - recall: 0.8189\n",
            "Epoch 170/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3897 - accuracy: 0.8297 - precision: 0.8322 - recall: 0.8259\n",
            "Epoch 171/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4020 - accuracy: 0.8297 - precision: 0.8268 - recall: 0.8341\n",
            "Epoch 172/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3930 - accuracy: 0.8247 - precision: 0.8275 - recall: 0.8202\n",
            "Epoch 173/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3887 - accuracy: 0.8256 - precision: 0.8253 - recall: 0.8259\n",
            "Epoch 174/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3886 - accuracy: 0.8247 - precision: 0.8275 - recall: 0.8202\n",
            "Epoch 175/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3926 - accuracy: 0.8272 - precision: 0.8275 - recall: 0.8265\n",
            "Epoch 176/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3957 - accuracy: 0.8234 - precision: 0.8181 - recall: 0.8315\n",
            "Epoch 177/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3880 - accuracy: 0.8231 - precision: 0.8290 - recall: 0.8139\n",
            "Epoch 178/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3927 - accuracy: 0.8247 - precision: 0.8242 - recall: 0.8252\n",
            "Epoch 179/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3865 - accuracy: 0.8278 - precision: 0.8303 - recall: 0.8240\n",
            "Epoch 180/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3811 - accuracy: 0.8291 - precision: 0.8341 - recall: 0.8215\n",
            "Epoch 181/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3847 - accuracy: 0.8341 - precision: 0.8379 - recall: 0.8284\n",
            "Epoch 182/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3864 - accuracy: 0.8259 - precision: 0.8267 - recall: 0.8246\n",
            "Epoch 183/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3892 - accuracy: 0.8221 - precision: 0.8241 - recall: 0.8189\n",
            "Epoch 184/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3857 - accuracy: 0.8278 - precision: 0.8337 - recall: 0.8189\n",
            "Epoch 185/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3872 - accuracy: 0.8174 - precision: 0.8192 - recall: 0.8145\n",
            "Epoch 186/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3840 - accuracy: 0.8316 - precision: 0.8311 - recall: 0.8322\n",
            "Epoch 187/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3884 - accuracy: 0.8269 - precision: 0.8266 - recall: 0.8271\n",
            "Epoch 188/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3910 - accuracy: 0.8272 - precision: 0.8313 - recall: 0.8208\n",
            "Epoch 189/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3920 - accuracy: 0.8221 - precision: 0.8287 - recall: 0.8120\n",
            "Epoch 190/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3929 - accuracy: 0.8190 - precision: 0.8238 - recall: 0.8114\n",
            "Epoch 191/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3920 - accuracy: 0.8199 - precision: 0.8122 - recall: 0.8322\n",
            "Epoch 192/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3843 - accuracy: 0.8319 - precision: 0.8304 - recall: 0.8341\n",
            "Epoch 193/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3856 - accuracy: 0.8262 - precision: 0.8235 - recall: 0.8303\n",
            "Epoch 194/600\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.3805 - accuracy: 0.8335 - precision: 0.8334 - recall: 0.8334\n",
            "Epoch 195/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3871 - accuracy: 0.8240 - precision: 0.8228 - recall: 0.8259\n",
            "Epoch 196/600\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.3858 - accuracy: 0.8341 - precision: 0.8423 - recall: 0.8221\n",
            "Epoch 197/600\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.3809 - accuracy: 0.8307 - precision: 0.8338 - recall: 0.8259\n",
            "Epoch 198/600\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.3781 - accuracy: 0.8366 - precision: 0.8426 - recall: 0.8278\n",
            "Epoch 199/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3818 - accuracy: 0.8322 - precision: 0.8305 - recall: 0.8347\n",
            "Epoch 200/600\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3822 - accuracy: 0.8335 - precision: 0.8356 - recall: 0.8303\n",
            "Epoch 201/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3822 - accuracy: 0.8266 - precision: 0.8298 - recall: 0.8215\n",
            "Epoch 202/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3799 - accuracy: 0.8319 - precision: 0.8300 - recall: 0.8347\n",
            "Epoch 203/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3831 - accuracy: 0.8310 - precision: 0.8301 - recall: 0.8322\n",
            "Epoch 204/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3778 - accuracy: 0.8348 - precision: 0.8343 - recall: 0.8353\n",
            "Epoch 205/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3795 - accuracy: 0.8291 - precision: 0.8320 - recall: 0.8246\n",
            "Epoch 206/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3740 - accuracy: 0.8325 - precision: 0.8340 - recall: 0.8303\n",
            "Epoch 207/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3785 - accuracy: 0.8344 - precision: 0.8372 - recall: 0.8303\n",
            "Epoch 208/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3772 - accuracy: 0.8300 - precision: 0.8361 - recall: 0.8208\n",
            "Epoch 209/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3753 - accuracy: 0.8291 - precision: 0.8354 - recall: 0.8196\n",
            "Epoch 210/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3817 - accuracy: 0.8316 - precision: 0.8332 - recall: 0.8290\n",
            "Epoch 211/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3840 - accuracy: 0.8379 - precision: 0.8316 - recall: 0.8473\n",
            "Epoch 212/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3708 - accuracy: 0.8310 - precision: 0.8272 - recall: 0.8366\n",
            "Epoch 213/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3719 - accuracy: 0.8354 - precision: 0.8370 - recall: 0.8328\n",
            "Epoch 214/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3682 - accuracy: 0.8430 - precision: 0.8429 - recall: 0.8429\n",
            "Epoch 215/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3833 - accuracy: 0.8344 - precision: 0.8308 - recall: 0.8397\n",
            "Epoch 216/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3716 - accuracy: 0.8344 - precision: 0.8350 - recall: 0.8334\n",
            "Epoch 217/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3851 - accuracy: 0.8231 - precision: 0.8274 - recall: 0.8164\n",
            "Epoch 218/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3773 - accuracy: 0.8284 - precision: 0.8292 - recall: 0.8271\n",
            "Epoch 219/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3698 - accuracy: 0.8348 - precision: 0.8305 - recall: 0.8410\n",
            "Epoch 220/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3685 - accuracy: 0.8335 - precision: 0.8373 - recall: 0.8278\n",
            "Epoch 221/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3665 - accuracy: 0.8385 - precision: 0.8385 - recall: 0.8385\n",
            "Epoch 222/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3729 - accuracy: 0.8284 - precision: 0.8272 - recall: 0.8303\n",
            "Epoch 223/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3725 - accuracy: 0.8363 - precision: 0.8361 - recall: 0.8366\n",
            "Epoch 224/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3697 - accuracy: 0.8395 - precision: 0.8384 - recall: 0.8410\n",
            "Epoch 225/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3731 - accuracy: 0.8363 - precision: 0.8340 - recall: 0.8397\n",
            "Epoch 226/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3769 - accuracy: 0.8335 - precision: 0.8322 - recall: 0.8353\n",
            "Epoch 227/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3729 - accuracy: 0.8281 - precision: 0.8299 - recall: 0.8252\n",
            "Epoch 228/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3685 - accuracy: 0.8392 - precision: 0.8370 - recall: 0.8423\n",
            "Epoch 229/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3686 - accuracy: 0.8341 - precision: 0.8303 - recall: 0.8397\n",
            "Epoch 230/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3738 - accuracy: 0.8335 - precision: 0.8339 - recall: 0.8328\n",
            "Epoch 231/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3658 - accuracy: 0.8404 - precision: 0.8417 - recall: 0.8385\n",
            "Epoch 232/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3717 - accuracy: 0.8370 - precision: 0.8367 - recall: 0.8372\n",
            "Epoch 233/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3649 - accuracy: 0.8338 - precision: 0.8331 - recall: 0.8347\n",
            "Epoch 234/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3741 - accuracy: 0.8376 - precision: 0.8286 - recall: 0.8511\n",
            "Epoch 235/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3701 - accuracy: 0.8344 - precision: 0.8346 - recall: 0.8341\n",
            "Epoch 236/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3815 - accuracy: 0.8291 - precision: 0.8197 - recall: 0.8435\n",
            "Epoch 237/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3697 - accuracy: 0.8395 - precision: 0.8422 - recall: 0.8353\n",
            "Epoch 238/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3668 - accuracy: 0.8439 - precision: 0.8467 - recall: 0.8397\n",
            "Epoch 239/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3709 - accuracy: 0.8379 - precision: 0.8320 - recall: 0.8467\n",
            "Epoch 240/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3767 - accuracy: 0.8338 - precision: 0.8315 - recall: 0.8372\n",
            "Epoch 241/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3692 - accuracy: 0.8363 - precision: 0.8323 - recall: 0.8423\n",
            "Epoch 242/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3591 - accuracy: 0.8389 - precision: 0.8352 - recall: 0.8442\n",
            "Epoch 243/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3746 - accuracy: 0.8332 - precision: 0.8321 - recall: 0.8347\n",
            "Epoch 244/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3711 - accuracy: 0.8316 - precision: 0.8320 - recall: 0.8309\n",
            "Epoch 245/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3603 - accuracy: 0.8348 - precision: 0.8351 - recall: 0.8341\n",
            "Epoch 246/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3687 - accuracy: 0.8382 - precision: 0.8418 - recall: 0.8328\n",
            "Epoch 247/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3595 - accuracy: 0.8417 - precision: 0.8412 - recall: 0.8423\n",
            "Epoch 248/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3776 - accuracy: 0.8329 - precision: 0.8278 - recall: 0.8404\n",
            "Epoch 249/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3690 - accuracy: 0.8360 - precision: 0.8347 - recall: 0.8379\n",
            "Epoch 250/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3642 - accuracy: 0.8385 - precision: 0.8381 - recall: 0.8391\n",
            "Epoch 251/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3649 - accuracy: 0.8426 - precision: 0.8402 - recall: 0.8461\n",
            "Epoch 252/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3659 - accuracy: 0.8360 - precision: 0.8351 - recall: 0.8372\n",
            "Epoch 253/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3657 - accuracy: 0.8373 - precision: 0.8310 - recall: 0.8467\n",
            "Epoch 254/600\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.3684 - accuracy: 0.8392 - precision: 0.8370 - recall: 0.8423\n",
            "Epoch 255/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3636 - accuracy: 0.8401 - precision: 0.8403 - recall: 0.8397\n",
            "Epoch 256/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3630 - accuracy: 0.8414 - precision: 0.8373 - recall: 0.8473\n",
            "Epoch 257/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3571 - accuracy: 0.8363 - precision: 0.8365 - recall: 0.8360\n",
            "Epoch 258/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3643 - accuracy: 0.8417 - precision: 0.8395 - recall: 0.8448\n",
            "Epoch 259/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3623 - accuracy: 0.8389 - precision: 0.8340 - recall: 0.8461\n",
            "Epoch 260/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3546 - accuracy: 0.8385 - precision: 0.8376 - recall: 0.8397\n",
            "Epoch 261/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3655 - accuracy: 0.8411 - precision: 0.8436 - recall: 0.8372\n",
            "Epoch 262/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3574 - accuracy: 0.8401 - precision: 0.8340 - recall: 0.8492\n",
            "Epoch 263/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3670 - accuracy: 0.8370 - precision: 0.8346 - recall: 0.8404\n",
            "Epoch 264/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3558 - accuracy: 0.8398 - precision: 0.8372 - recall: 0.8435\n",
            "Epoch 265/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3569 - accuracy: 0.8376 - precision: 0.8373 - recall: 0.8379\n",
            "Epoch 266/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3625 - accuracy: 0.8436 - precision: 0.8393 - recall: 0.8498\n",
            "Epoch 267/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3494 - accuracy: 0.8458 - precision: 0.8434 - recall: 0.8492\n",
            "Epoch 268/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3491 - accuracy: 0.8442 - precision: 0.8369 - recall: 0.8549\n",
            "Epoch 269/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3588 - accuracy: 0.8436 - precision: 0.8355 - recall: 0.8555\n",
            "Epoch 270/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3652 - accuracy: 0.8366 - precision: 0.8400 - recall: 0.8315\n",
            "Epoch 271/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3565 - accuracy: 0.8414 - precision: 0.8398 - recall: 0.8435\n",
            "Epoch 272/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3644 - accuracy: 0.8363 - precision: 0.8331 - recall: 0.8410\n",
            "Epoch 273/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3599 - accuracy: 0.8417 - precision: 0.8382 - recall: 0.8467\n",
            "Epoch 274/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3555 - accuracy: 0.8344 - precision: 0.8308 - recall: 0.8397\n",
            "Epoch 275/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3455 - accuracy: 0.8521 - precision: 0.8470 - recall: 0.8593\n",
            "Epoch 276/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3578 - accuracy: 0.8395 - precision: 0.8329 - recall: 0.8492\n",
            "Epoch 277/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3504 - accuracy: 0.8474 - precision: 0.8478 - recall: 0.8467\n",
            "Epoch 278/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3607 - accuracy: 0.8439 - precision: 0.8385 - recall: 0.8517\n",
            "Epoch 279/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3554 - accuracy: 0.8471 - precision: 0.8481 - recall: 0.8454\n",
            "Epoch 280/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3508 - accuracy: 0.8436 - precision: 0.8397 - recall: 0.8492\n",
            "Epoch 281/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3588 - accuracy: 0.8458 - precision: 0.8429 - recall: 0.8498\n",
            "Epoch 282/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3541 - accuracy: 0.8448 - precision: 0.8401 - recall: 0.8517\n",
            "Epoch 283/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3614 - accuracy: 0.8464 - precision: 0.8410 - recall: 0.8543\n",
            "Epoch 284/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3537 - accuracy: 0.8455 - precision: 0.8403 - recall: 0.8530\n",
            "Epoch 285/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3526 - accuracy: 0.8439 - precision: 0.8368 - recall: 0.8543\n",
            "Epoch 286/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3528 - accuracy: 0.8448 - precision: 0.8448 - recall: 0.8448\n",
            "Epoch 287/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3497 - accuracy: 0.8455 - precision: 0.8411 - recall: 0.8517\n",
            "Epoch 288/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3570 - accuracy: 0.8430 - precision: 0.8361 - recall: 0.8530\n",
            "Epoch 289/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3542 - accuracy: 0.8442 - precision: 0.8412 - recall: 0.8486\n",
            "Epoch 290/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3593 - accuracy: 0.8464 - precision: 0.8427 - recall: 0.8517\n",
            "Epoch 291/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3508 - accuracy: 0.8407 - precision: 0.8396 - recall: 0.8423\n",
            "Epoch 292/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3476 - accuracy: 0.8414 - precision: 0.8398 - recall: 0.8435\n",
            "Epoch 293/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3487 - accuracy: 0.8524 - precision: 0.8462 - recall: 0.8612\n",
            "Epoch 294/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3522 - accuracy: 0.8467 - precision: 0.8390 - recall: 0.8580\n",
            "Epoch 295/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3527 - accuracy: 0.8452 - precision: 0.8423 - recall: 0.8492\n",
            "Epoch 296/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3639 - accuracy: 0.8373 - precision: 0.8343 - recall: 0.8416\n",
            "Epoch 297/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3571 - accuracy: 0.8458 - precision: 0.8425 - recall: 0.8505\n",
            "Epoch 298/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3486 - accuracy: 0.8458 - precision: 0.8379 - recall: 0.8574\n",
            "Epoch 299/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3517 - accuracy: 0.8448 - precision: 0.8426 - recall: 0.8479\n",
            "Epoch 300/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3492 - accuracy: 0.8445 - precision: 0.8430 - recall: 0.8467\n",
            "Epoch 301/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3522 - accuracy: 0.8502 - precision: 0.8417 - recall: 0.8625\n",
            "Epoch 302/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3631 - accuracy: 0.8341 - precision: 0.8303 - recall: 0.8397\n",
            "Epoch 303/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3504 - accuracy: 0.8411 - precision: 0.8389 - recall: 0.8442\n",
            "Epoch 304/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3633 - accuracy: 0.8474 - precision: 0.8447 - recall: 0.8511\n",
            "Epoch 305/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3479 - accuracy: 0.8499 - precision: 0.8485 - recall: 0.8517\n",
            "Epoch 306/600\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.3483 - accuracy: 0.8471 - precision: 0.8429 - recall: 0.8530\n",
            "Epoch 307/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3433 - accuracy: 0.8477 - precision: 0.8405 - recall: 0.8580\n",
            "Epoch 308/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3504 - accuracy: 0.8480 - precision: 0.8402 - recall: 0.8593\n",
            "Epoch 309/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3537 - accuracy: 0.8348 - precision: 0.8318 - recall: 0.8391\n",
            "Epoch 310/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3513 - accuracy: 0.8452 - precision: 0.8398 - recall: 0.8530\n",
            "Epoch 311/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3450 - accuracy: 0.8486 - precision: 0.8442 - recall: 0.8549\n",
            "Epoch 312/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3475 - accuracy: 0.8496 - precision: 0.8386 - recall: 0.8656\n",
            "Epoch 313/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3392 - accuracy: 0.8543 - precision: 0.8507 - recall: 0.8593\n",
            "Epoch 314/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3558 - accuracy: 0.8376 - precision: 0.8307 - recall: 0.8479\n",
            "Epoch 315/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3473 - accuracy: 0.8448 - precision: 0.8426 - recall: 0.8479\n",
            "Epoch 316/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3452 - accuracy: 0.8439 - precision: 0.8436 - recall: 0.8442\n",
            "Epoch 317/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3405 - accuracy: 0.8489 - precision: 0.8448 - recall: 0.8549\n",
            "Epoch 318/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3467 - accuracy: 0.8426 - precision: 0.8377 - recall: 0.8498\n",
            "Epoch 319/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3443 - accuracy: 0.8486 - precision: 0.8421 - recall: 0.8580\n",
            "Epoch 320/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3497 - accuracy: 0.8489 - precision: 0.8478 - recall: 0.8505\n",
            "Epoch 321/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3557 - accuracy: 0.8455 - precision: 0.8407 - recall: 0.8524\n",
            "Epoch 322/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3501 - accuracy: 0.8489 - precision: 0.8405 - recall: 0.8612\n",
            "Epoch 323/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3440 - accuracy: 0.8489 - precision: 0.8397 - recall: 0.8625\n",
            "Epoch 324/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3443 - accuracy: 0.8474 - precision: 0.8469 - recall: 0.8479\n",
            "Epoch 325/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3414 - accuracy: 0.8461 - precision: 0.8392 - recall: 0.8562\n",
            "Epoch 326/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3503 - accuracy: 0.8430 - precision: 0.8429 - recall: 0.8429\n",
            "Epoch 327/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3387 - accuracy: 0.8543 - precision: 0.8507 - recall: 0.8593\n",
            "Epoch 328/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3535 - accuracy: 0.8414 - precision: 0.8381 - recall: 0.8461\n",
            "Epoch 329/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3399 - accuracy: 0.8584 - precision: 0.8532 - recall: 0.8656\n",
            "Epoch 330/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3446 - accuracy: 0.8445 - precision: 0.8383 - recall: 0.8536\n",
            "Epoch 331/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3427 - accuracy: 0.8502 - precision: 0.8482 - recall: 0.8530\n",
            "Epoch 332/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3386 - accuracy: 0.8530 - precision: 0.8508 - recall: 0.8562\n",
            "Epoch 333/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3481 - accuracy: 0.8461 - precision: 0.8396 - recall: 0.8555\n",
            "Epoch 334/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3414 - accuracy: 0.8461 - precision: 0.8392 - recall: 0.8562\n",
            "Epoch 335/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3429 - accuracy: 0.8534 - precision: 0.8453 - recall: 0.8650\n",
            "Epoch 336/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3408 - accuracy: 0.8524 - precision: 0.8437 - recall: 0.8650\n",
            "Epoch 337/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3496 - accuracy: 0.8426 - precision: 0.8407 - recall: 0.8454\n",
            "Epoch 338/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3414 - accuracy: 0.8515 - precision: 0.8430 - recall: 0.8637\n",
            "Epoch 339/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3403 - accuracy: 0.8508 - precision: 0.8453 - recall: 0.8587\n",
            "Epoch 340/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3494 - accuracy: 0.8496 - precision: 0.8471 - recall: 0.8530\n",
            "Epoch 341/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3414 - accuracy: 0.8455 - precision: 0.8378 - recall: 0.8568\n",
            "Epoch 342/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3470 - accuracy: 0.8480 - precision: 0.8415 - recall: 0.8574\n",
            "Epoch 343/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3432 - accuracy: 0.8436 - precision: 0.8418 - recall: 0.8461\n",
            "Epoch 344/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3410 - accuracy: 0.8530 - precision: 0.8508 - recall: 0.8562\n",
            "Epoch 345/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3308 - accuracy: 0.8546 - precision: 0.8482 - recall: 0.8637\n",
            "Epoch 346/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3424 - accuracy: 0.8512 - precision: 0.8498 - recall: 0.8530\n",
            "Epoch 347/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3384 - accuracy: 0.8508 - precision: 0.8466 - recall: 0.8568\n",
            "Epoch 348/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3492 - accuracy: 0.8480 - precision: 0.8423 - recall: 0.8562\n",
            "Epoch 349/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3417 - accuracy: 0.8426 - precision: 0.8377 - recall: 0.8498\n",
            "Epoch 350/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3327 - accuracy: 0.8515 - precision: 0.8486 - recall: 0.8555\n",
            "Epoch 351/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3432 - accuracy: 0.8496 - precision: 0.8450 - recall: 0.8562\n",
            "Epoch 352/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3440 - accuracy: 0.8512 - precision: 0.8538 - recall: 0.8473\n",
            "Epoch 353/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3365 - accuracy: 0.8411 - precision: 0.8397 - recall: 0.8429\n",
            "Epoch 354/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3351 - accuracy: 0.8575 - precision: 0.8588 - recall: 0.8555\n",
            "Epoch 355/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3416 - accuracy: 0.8430 - precision: 0.8442 - recall: 0.8410\n",
            "Epoch 356/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3396 - accuracy: 0.8499 - precision: 0.8451 - recall: 0.8568\n",
            "Epoch 357/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3361 - accuracy: 0.8508 - precision: 0.8479 - recall: 0.8549\n",
            "Epoch 358/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3339 - accuracy: 0.8467 - precision: 0.8463 - recall: 0.8473\n",
            "Epoch 359/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3332 - accuracy: 0.8562 - precision: 0.8553 - recall: 0.8574\n",
            "Epoch 360/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3357 - accuracy: 0.8534 - precision: 0.8518 - recall: 0.8555\n",
            "Epoch 361/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3317 - accuracy: 0.8590 - precision: 0.8525 - recall: 0.8681\n",
            "Epoch 362/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3367 - accuracy: 0.8530 - precision: 0.8495 - recall: 0.8580\n",
            "Epoch 363/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3313 - accuracy: 0.8553 - precision: 0.8497 - recall: 0.8631\n",
            "Epoch 364/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3295 - accuracy: 0.8562 - precision: 0.8526 - recall: 0.8612\n",
            "Epoch 365/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3344 - accuracy: 0.8483 - precision: 0.8429 - recall: 0.8562\n",
            "Epoch 366/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3275 - accuracy: 0.8600 - precision: 0.8581 - recall: 0.8625\n",
            "Epoch 367/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3381 - accuracy: 0.8471 - precision: 0.8412 - recall: 0.8555\n",
            "Epoch 368/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3345 - accuracy: 0.8537 - precision: 0.8453 - recall: 0.8656\n",
            "Epoch 369/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3420 - accuracy: 0.8471 - precision: 0.8429 - recall: 0.8530\n",
            "Epoch 370/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3344 - accuracy: 0.8524 - precision: 0.8441 - recall: 0.8644\n",
            "Epoch 371/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3413 - accuracy: 0.8499 - precision: 0.8451 - recall: 0.8568\n",
            "Epoch 372/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3395 - accuracy: 0.8477 - precision: 0.8461 - recall: 0.8498\n",
            "Epoch 373/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3271 - accuracy: 0.8587 - precision: 0.8486 - recall: 0.8732\n",
            "Epoch 374/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3342 - accuracy: 0.8496 - precision: 0.8462 - recall: 0.8543\n",
            "Epoch 375/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3295 - accuracy: 0.8556 - precision: 0.8502 - recall: 0.8631\n",
            "Epoch 376/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3275 - accuracy: 0.8578 - precision: 0.8571 - recall: 0.8587\n",
            "Epoch 377/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3297 - accuracy: 0.8587 - precision: 0.8546 - recall: 0.8644\n",
            "Epoch 378/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3323 - accuracy: 0.8568 - precision: 0.8559 - recall: 0.8580\n",
            "Epoch 379/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3282 - accuracy: 0.8559 - precision: 0.8499 - recall: 0.8644\n",
            "Epoch 380/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3242 - accuracy: 0.8600 - precision: 0.8555 - recall: 0.8662\n",
            "Epoch 381/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3301 - accuracy: 0.8565 - precision: 0.8466 - recall: 0.8707\n",
            "Epoch 382/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3366 - accuracy: 0.8527 - precision: 0.8459 - recall: 0.8625\n",
            "Epoch 383/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3392 - accuracy: 0.8515 - precision: 0.8521 - recall: 0.8505\n",
            "Epoch 384/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3268 - accuracy: 0.8553 - precision: 0.8501 - recall: 0.8625\n",
            "Epoch 385/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3272 - accuracy: 0.8540 - precision: 0.8515 - recall: 0.8574\n",
            "Epoch 386/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3263 - accuracy: 0.8568 - precision: 0.8545 - recall: 0.8599\n",
            "Epoch 387/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3343 - accuracy: 0.8559 - precision: 0.8521 - recall: 0.8612\n",
            "Epoch 388/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3304 - accuracy: 0.8540 - precision: 0.8467 - recall: 0.8644\n",
            "Epoch 389/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3222 - accuracy: 0.8584 - precision: 0.8515 - recall: 0.8681\n",
            "Epoch 390/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3411 - accuracy: 0.8477 - precision: 0.8474 - recall: 0.8479\n",
            "Epoch 391/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3270 - accuracy: 0.8597 - precision: 0.8580 - recall: 0.8618\n",
            "Epoch 392/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3348 - accuracy: 0.8534 - precision: 0.8509 - recall: 0.8568\n",
            "Epoch 393/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3308 - accuracy: 0.8556 - precision: 0.8493 - recall: 0.8644\n",
            "Epoch 394/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3295 - accuracy: 0.8477 - precision: 0.8422 - recall: 0.8555\n",
            "Epoch 395/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3258 - accuracy: 0.8527 - precision: 0.8503 - recall: 0.8562\n",
            "Epoch 396/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3220 - accuracy: 0.8549 - precision: 0.8509 - recall: 0.8606\n",
            "Epoch 397/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3271 - accuracy: 0.8502 - precision: 0.8456 - recall: 0.8568\n",
            "Epoch 398/600\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.3386 - accuracy: 0.8537 - precision: 0.8458 - recall: 0.8650\n",
            "Epoch 399/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3167 - accuracy: 0.8609 - precision: 0.8566 - recall: 0.8669\n",
            "Epoch 400/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3234 - accuracy: 0.8527 - precision: 0.8446 - recall: 0.8644\n",
            "Epoch 401/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3239 - accuracy: 0.8597 - precision: 0.8585 - recall: 0.8612\n",
            "Epoch 402/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3392 - accuracy: 0.8527 - precision: 0.8529 - recall: 0.8524\n",
            "Epoch 403/600\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.3313 - accuracy: 0.8575 - precision: 0.8490 - recall: 0.8694\n",
            "Epoch 404/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3293 - accuracy: 0.8568 - precision: 0.8450 - recall: 0.8738\n",
            "Epoch 405/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3217 - accuracy: 0.8597 - precision: 0.8571 - recall: 0.8631\n",
            "Epoch 406/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3357 - accuracy: 0.8483 - precision: 0.8454 - recall: 0.8524\n",
            "Epoch 407/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3288 - accuracy: 0.8521 - precision: 0.8457 - recall: 0.8612\n",
            "Epoch 408/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3243 - accuracy: 0.8603 - precision: 0.8555 - recall: 0.8669\n",
            "Epoch 409/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3331 - accuracy: 0.8505 - precision: 0.8448 - recall: 0.8587\n",
            "Epoch 410/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3139 - accuracy: 0.8625 - precision: 0.8579 - recall: 0.8688\n",
            "Epoch 411/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3301 - accuracy: 0.8534 - precision: 0.8474 - recall: 0.8618\n",
            "Epoch 412/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3356 - accuracy: 0.8518 - precision: 0.8401 - recall: 0.8688\n",
            "Epoch 413/600\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3335 - accuracy: 0.8505 - precision: 0.8431 - recall: 0.8612\n",
            "Epoch 414/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3249 - accuracy: 0.8575 - precision: 0.8538 - recall: 0.8625\n",
            "Epoch 415/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3271 - accuracy: 0.8559 - precision: 0.8516 - recall: 0.8618\n",
            "Epoch 416/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3183 - accuracy: 0.8609 - precision: 0.8588 - recall: 0.8637\n",
            "Epoch 417/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3309 - accuracy: 0.8524 - precision: 0.8475 - recall: 0.8593\n",
            "Epoch 418/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3235 - accuracy: 0.8594 - precision: 0.8571 - recall: 0.8625\n",
            "Epoch 419/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3200 - accuracy: 0.8587 - precision: 0.8551 - recall: 0.8637\n",
            "Epoch 420/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3177 - accuracy: 0.8537 - precision: 0.8475 - recall: 0.8625\n",
            "Epoch 421/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3272 - accuracy: 0.8559 - precision: 0.8481 - recall: 0.8669\n",
            "Epoch 422/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3287 - accuracy: 0.8543 - precision: 0.8494 - recall: 0.8612\n",
            "Epoch 423/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3267 - accuracy: 0.8546 - precision: 0.8478 - recall: 0.8644\n",
            "Epoch 424/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3304 - accuracy: 0.8565 - precision: 0.8527 - recall: 0.8618\n",
            "Epoch 425/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3311 - accuracy: 0.8527 - precision: 0.8476 - recall: 0.8599\n",
            "Epoch 426/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3272 - accuracy: 0.8549 - precision: 0.8496 - recall: 0.8625\n",
            "Epoch 427/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3253 - accuracy: 0.8477 - precision: 0.8431 - recall: 0.8543\n",
            "Epoch 428/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3220 - accuracy: 0.8549 - precision: 0.8474 - recall: 0.8656\n",
            "Epoch 429/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3201 - accuracy: 0.8559 - precision: 0.8565 - recall: 0.8549\n",
            "Epoch 430/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3173 - accuracy: 0.8543 - precision: 0.8485 - recall: 0.8625\n",
            "Epoch 431/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3274 - accuracy: 0.8540 - precision: 0.8573 - recall: 0.8492\n",
            "Epoch 432/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3163 - accuracy: 0.8578 - precision: 0.8531 - recall: 0.8644\n",
            "Epoch 433/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3257 - accuracy: 0.8562 - precision: 0.8557 - recall: 0.8568\n",
            "Epoch 434/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3263 - accuracy: 0.8527 - precision: 0.8451 - recall: 0.8637\n",
            "Epoch 435/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3283 - accuracy: 0.8543 - precision: 0.8534 - recall: 0.8555\n",
            "Epoch 436/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3144 - accuracy: 0.8587 - precision: 0.8560 - recall: 0.8625\n",
            "Epoch 437/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3251 - accuracy: 0.8540 - precision: 0.8472 - recall: 0.8637\n",
            "Epoch 438/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3253 - accuracy: 0.8571 - precision: 0.8520 - recall: 0.8644\n",
            "Epoch 439/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3233 - accuracy: 0.8641 - precision: 0.8588 - recall: 0.8713\n",
            "Epoch 440/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3156 - accuracy: 0.8616 - precision: 0.8555 - recall: 0.8700\n",
            "Epoch 441/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3274 - accuracy: 0.8584 - precision: 0.8554 - recall: 0.8625\n",
            "Epoch 442/600\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.3110 - accuracy: 0.8631 - precision: 0.8546 - recall: 0.8751\n",
            "Epoch 443/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3217 - accuracy: 0.8568 - precision: 0.8489 - recall: 0.8681\n",
            "Epoch 444/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3186 - accuracy: 0.8562 - precision: 0.8575 - recall: 0.8543\n",
            "Epoch 445/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3172 - accuracy: 0.8568 - precision: 0.8493 - recall: 0.8675\n",
            "Epoch 446/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3253 - accuracy: 0.8600 - precision: 0.8577 - recall: 0.8631\n",
            "Epoch 447/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3114 - accuracy: 0.8650 - precision: 0.8600 - recall: 0.8719\n",
            "Epoch 448/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3282 - accuracy: 0.8518 - precision: 0.8461 - recall: 0.8599\n",
            "Epoch 449/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3183 - accuracy: 0.8672 - precision: 0.8647 - recall: 0.8707\n",
            "Epoch 450/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3131 - accuracy: 0.8616 - precision: 0.8541 - recall: 0.8719\n",
            "Epoch 451/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3217 - accuracy: 0.8603 - precision: 0.8529 - recall: 0.8707\n",
            "Epoch 452/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3080 - accuracy: 0.8657 - precision: 0.8652 - recall: 0.8662\n",
            "Epoch 453/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3225 - accuracy: 0.8587 - precision: 0.8633 - recall: 0.8524\n",
            "Epoch 454/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3227 - accuracy: 0.8502 - precision: 0.8409 - recall: 0.8637\n",
            "Epoch 455/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3275 - accuracy: 0.8562 - precision: 0.8566 - recall: 0.8555\n",
            "Epoch 456/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3258 - accuracy: 0.8625 - precision: 0.8615 - recall: 0.8637\n",
            "Epoch 457/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3188 - accuracy: 0.8556 - precision: 0.8555 - recall: 0.8555\n",
            "Epoch 458/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3163 - accuracy: 0.8587 - precision: 0.8529 - recall: 0.8669\n",
            "Epoch 459/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3286 - accuracy: 0.8584 - precision: 0.8519 - recall: 0.8675\n",
            "Epoch 460/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3182 - accuracy: 0.8612 - precision: 0.8558 - recall: 0.8688\n",
            "Epoch 461/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3249 - accuracy: 0.8556 - precision: 0.8502 - recall: 0.8631\n",
            "Epoch 462/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3163 - accuracy: 0.8575 - precision: 0.8565 - recall: 0.8587\n",
            "Epoch 463/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3239 - accuracy: 0.8612 - precision: 0.8571 - recall: 0.8669\n",
            "Epoch 464/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3146 - accuracy: 0.8622 - precision: 0.8651 - recall: 0.8580\n",
            "Epoch 465/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3204 - accuracy: 0.8575 - precision: 0.8565 - recall: 0.8587\n",
            "Epoch 466/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3229 - accuracy: 0.8546 - precision: 0.8499 - recall: 0.8612\n",
            "Epoch 467/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3115 - accuracy: 0.8609 - precision: 0.8557 - recall: 0.8681\n",
            "Epoch 468/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3218 - accuracy: 0.8553 - precision: 0.8519 - recall: 0.8599\n",
            "Epoch 469/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3131 - accuracy: 0.8660 - precision: 0.8639 - recall: 0.8688\n",
            "Epoch 470/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3208 - accuracy: 0.8594 - precision: 0.8557 - recall: 0.8644\n",
            "Epoch 471/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3206 - accuracy: 0.8597 - precision: 0.8554 - recall: 0.8656\n",
            "Epoch 472/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3202 - accuracy: 0.8609 - precision: 0.8634 - recall: 0.8574\n",
            "Epoch 473/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3157 - accuracy: 0.8575 - precision: 0.8543 - recall: 0.8618\n",
            "Epoch 474/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3201 - accuracy: 0.8530 - precision: 0.8512 - recall: 0.8555\n",
            "Epoch 475/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3303 - accuracy: 0.8556 - precision: 0.8498 - recall: 0.8637\n",
            "Epoch 476/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3215 - accuracy: 0.8590 - precision: 0.8561 - recall: 0.8631\n",
            "Epoch 477/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3147 - accuracy: 0.8606 - precision: 0.8565 - recall: 0.8662\n",
            "Epoch 478/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3142 - accuracy: 0.8616 - precision: 0.8568 - recall: 0.8681\n",
            "Epoch 479/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3151 - accuracy: 0.8575 - precision: 0.8525 - recall: 0.8644\n",
            "Epoch 480/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3183 - accuracy: 0.8603 - precision: 0.8587 - recall: 0.8625\n",
            "Epoch 481/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3169 - accuracy: 0.8600 - precision: 0.8599 - recall: 0.8599\n",
            "Epoch 482/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3073 - accuracy: 0.8638 - precision: 0.8642 - recall: 0.8631\n",
            "Epoch 483/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3173 - accuracy: 0.8616 - precision: 0.8590 - recall: 0.8650\n",
            "Epoch 484/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3274 - accuracy: 0.8496 - precision: 0.8386 - recall: 0.8656\n",
            "Epoch 485/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3138 - accuracy: 0.8634 - precision: 0.8569 - recall: 0.8726\n",
            "Epoch 486/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3103 - accuracy: 0.8619 - precision: 0.8641 - recall: 0.8587\n",
            "Epoch 487/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3250 - accuracy: 0.8543 - precision: 0.8477 - recall: 0.8637\n",
            "Epoch 488/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3150 - accuracy: 0.8578 - precision: 0.8526 - recall: 0.8650\n",
            "Epoch 489/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3218 - accuracy: 0.8556 - precision: 0.8485 - recall: 0.8656\n",
            "Epoch 490/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3173 - accuracy: 0.8609 - precision: 0.8597 - recall: 0.8625\n",
            "Epoch 491/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3209 - accuracy: 0.8619 - precision: 0.8618 - recall: 0.8618\n",
            "Epoch 492/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3214 - accuracy: 0.8575 - precision: 0.8516 - recall: 0.8656\n",
            "Epoch 493/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3169 - accuracy: 0.8628 - precision: 0.8594 - recall: 0.8675\n",
            "Epoch 494/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3153 - accuracy: 0.8612 - precision: 0.8649 - recall: 0.8562\n",
            "Epoch 495/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3060 - accuracy: 0.8660 - precision: 0.8616 - recall: 0.8719\n",
            "Epoch 496/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3177 - accuracy: 0.8628 - precision: 0.8563 - recall: 0.8719\n",
            "Epoch 497/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3136 - accuracy: 0.8625 - precision: 0.8620 - recall: 0.8631\n",
            "Epoch 498/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3113 - accuracy: 0.8672 - precision: 0.8633 - recall: 0.8726\n",
            "Epoch 499/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3032 - accuracy: 0.8638 - precision: 0.8587 - recall: 0.8707\n",
            "Epoch 500/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3166 - accuracy: 0.8628 - precision: 0.8580 - recall: 0.8694\n",
            "Epoch 501/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3113 - accuracy: 0.8619 - precision: 0.8587 - recall: 0.8662\n",
            "Epoch 502/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3189 - accuracy: 0.8581 - precision: 0.8505 - recall: 0.8688\n",
            "Epoch 503/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3145 - accuracy: 0.8638 - precision: 0.8610 - recall: 0.8675\n",
            "Epoch 504/600\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.3223 - accuracy: 0.8565 - precision: 0.8631 - recall: 0.8473\n",
            "Epoch 505/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3167 - accuracy: 0.8565 - precision: 0.8527 - recall: 0.8618\n",
            "Epoch 506/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3126 - accuracy: 0.8638 - precision: 0.8579 - recall: 0.8719\n",
            "Epoch 507/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3191 - accuracy: 0.8622 - precision: 0.8675 - recall: 0.8549\n",
            "Epoch 508/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3003 - accuracy: 0.8647 - precision: 0.8626 - recall: 0.8675\n",
            "Epoch 509/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3167 - accuracy: 0.8638 - precision: 0.8570 - recall: 0.8732\n",
            "Epoch 510/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3239 - accuracy: 0.8543 - precision: 0.8556 - recall: 0.8524\n",
            "Epoch 511/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3170 - accuracy: 0.8682 - precision: 0.8640 - recall: 0.8738\n",
            "Epoch 512/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3032 - accuracy: 0.8691 - precision: 0.8689 - recall: 0.8694\n",
            "Epoch 513/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3271 - accuracy: 0.8534 - precision: 0.8518 - recall: 0.8555\n",
            "Epoch 514/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3139 - accuracy: 0.8609 - precision: 0.8562 - recall: 0.8675\n",
            "Epoch 515/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3138 - accuracy: 0.8644 - precision: 0.8603 - recall: 0.8700\n",
            "Epoch 516/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3064 - accuracy: 0.8679 - precision: 0.8657 - recall: 0.8707\n",
            "Epoch 517/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3252 - accuracy: 0.8521 - precision: 0.8483 - recall: 0.8574\n",
            "Epoch 518/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3087 - accuracy: 0.8625 - precision: 0.8611 - recall: 0.8644\n",
            "Epoch 519/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3137 - accuracy: 0.8559 - precision: 0.8561 - recall: 0.8555\n",
            "Epoch 520/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3141 - accuracy: 0.8631 - precision: 0.8617 - recall: 0.8650\n",
            "Epoch 521/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3201 - accuracy: 0.8571 - precision: 0.8511 - recall: 0.8656\n",
            "Epoch 522/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3128 - accuracy: 0.8660 - precision: 0.8643 - recall: 0.8681\n",
            "Epoch 523/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3007 - accuracy: 0.8685 - precision: 0.8664 - recall: 0.8713\n",
            "Epoch 524/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3071 - accuracy: 0.8571 - precision: 0.8555 - recall: 0.8593\n",
            "Epoch 525/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3199 - accuracy: 0.8594 - precision: 0.8611 - recall: 0.8568\n",
            "Epoch 526/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3251 - accuracy: 0.8521 - precision: 0.8479 - recall: 0.8580\n",
            "Epoch 527/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3136 - accuracy: 0.8600 - precision: 0.8604 - recall: 0.8593\n",
            "Epoch 528/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3116 - accuracy: 0.8578 - precision: 0.8548 - recall: 0.8618\n",
            "Epoch 529/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3123 - accuracy: 0.8609 - precision: 0.8575 - recall: 0.8656\n",
            "Epoch 530/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3043 - accuracy: 0.8644 - precision: 0.8607 - recall: 0.8694\n",
            "Epoch 531/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3019 - accuracy: 0.8716 - precision: 0.8690 - recall: 0.8751\n",
            "Epoch 532/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3155 - accuracy: 0.8653 - precision: 0.8632 - recall: 0.8681\n",
            "Epoch 533/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3116 - accuracy: 0.8559 - precision: 0.8538 - recall: 0.8587\n",
            "Epoch 534/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3081 - accuracy: 0.8628 - precision: 0.8635 - recall: 0.8618\n",
            "Epoch 535/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3184 - accuracy: 0.8597 - precision: 0.8536 - recall: 0.8681\n",
            "Epoch 536/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3128 - accuracy: 0.8631 - precision: 0.8586 - recall: 0.8694\n",
            "Epoch 537/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3152 - accuracy: 0.8647 - precision: 0.8686 - recall: 0.8593\n",
            "Epoch 538/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3162 - accuracy: 0.8568 - precision: 0.8497 - recall: 0.8669\n",
            "Epoch 539/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3142 - accuracy: 0.8663 - precision: 0.8639 - recall: 0.8694\n",
            "Epoch 540/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3095 - accuracy: 0.8594 - precision: 0.8575 - recall: 0.8618\n",
            "Epoch 541/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3060 - accuracy: 0.8660 - precision: 0.8643 - recall: 0.8681\n",
            "Epoch 542/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3068 - accuracy: 0.8663 - precision: 0.8639 - recall: 0.8694\n",
            "Epoch 543/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3069 - accuracy: 0.8622 - precision: 0.8592 - recall: 0.8662\n",
            "Epoch 544/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3158 - accuracy: 0.8549 - precision: 0.8571 - recall: 0.8517\n",
            "Epoch 545/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3137 - accuracy: 0.8612 - precision: 0.8607 - recall: 0.8618\n",
            "Epoch 546/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3058 - accuracy: 0.8641 - precision: 0.8647 - recall: 0.8631\n",
            "Epoch 547/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3068 - accuracy: 0.8616 - precision: 0.8664 - recall: 0.8549\n",
            "Epoch 548/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3037 - accuracy: 0.8679 - precision: 0.8626 - recall: 0.8751\n",
            "Epoch 549/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3062 - accuracy: 0.8688 - precision: 0.8665 - recall: 0.8719\n",
            "Epoch 550/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3140 - accuracy: 0.8578 - precision: 0.8491 - recall: 0.8700\n",
            "Epoch 551/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3153 - accuracy: 0.8549 - precision: 0.8562 - recall: 0.8530\n",
            "Epoch 552/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3173 - accuracy: 0.8553 - precision: 0.8497 - recall: 0.8631\n",
            "Epoch 553/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3144 - accuracy: 0.8619 - precision: 0.8564 - recall: 0.8694\n",
            "Epoch 554/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3077 - accuracy: 0.8650 - precision: 0.8618 - recall: 0.8694\n",
            "Epoch 555/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3134 - accuracy: 0.8612 - precision: 0.8621 - recall: 0.8599\n",
            "Epoch 556/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3152 - accuracy: 0.8619 - precision: 0.8582 - recall: 0.8669\n",
            "Epoch 557/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3135 - accuracy: 0.8609 - precision: 0.8648 - recall: 0.8555\n",
            "Epoch 558/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3012 - accuracy: 0.8704 - precision: 0.8720 - recall: 0.8681\n",
            "Epoch 559/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3098 - accuracy: 0.8666 - precision: 0.8668 - recall: 0.8662\n",
            "Epoch 560/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3093 - accuracy: 0.8622 - precision: 0.8633 - recall: 0.8606\n",
            "Epoch 561/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3159 - accuracy: 0.8619 - precision: 0.8712 - recall: 0.8492\n",
            "Epoch 562/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3093 - accuracy: 0.8606 - precision: 0.8597 - recall: 0.8618\n",
            "Epoch 563/600\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.3015 - accuracy: 0.8619 - precision: 0.8609 - recall: 0.8631\n",
            "Epoch 564/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3095 - accuracy: 0.8622 - precision: 0.8628 - recall: 0.8612\n",
            "Epoch 565/600\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3030 - accuracy: 0.8647 - precision: 0.8599 - recall: 0.8713\n",
            "Epoch 566/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.2978 - accuracy: 0.8666 - precision: 0.8701 - recall: 0.8618\n",
            "Epoch 567/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3108 - accuracy: 0.8647 - precision: 0.8617 - recall: 0.8688\n",
            "Epoch 568/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3174 - accuracy: 0.8600 - precision: 0.8608 - recall: 0.8587\n",
            "Epoch 569/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3145 - accuracy: 0.8644 - precision: 0.8743 - recall: 0.8511\n",
            "Epoch 570/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3035 - accuracy: 0.8663 - precision: 0.8635 - recall: 0.8700\n",
            "Epoch 571/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3084 - accuracy: 0.8616 - precision: 0.8599 - recall: 0.8637\n",
            "Epoch 572/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3077 - accuracy: 0.8704 - precision: 0.8628 - recall: 0.8808\n",
            "Epoch 573/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3211 - accuracy: 0.8578 - precision: 0.8584 - recall: 0.8568\n",
            "Epoch 574/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3123 - accuracy: 0.8694 - precision: 0.8741 - recall: 0.8631\n",
            "Epoch 575/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3033 - accuracy: 0.8647 - precision: 0.8658 - recall: 0.8631\n",
            "Epoch 576/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3063 - accuracy: 0.8612 - precision: 0.8626 - recall: 0.8593\n",
            "Epoch 577/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3099 - accuracy: 0.8631 - precision: 0.8640 - recall: 0.8618\n",
            "Epoch 578/600\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.3216 - accuracy: 0.8515 - precision: 0.8534 - recall: 0.8486\n",
            "Epoch 579/600\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3034 - accuracy: 0.8669 - precision: 0.8673 - recall: 0.8662\n",
            "Epoch 580/600\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3228 - accuracy: 0.8565 - precision: 0.8553 - recall: 0.8580\n",
            "Epoch 581/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3033 - accuracy: 0.8675 - precision: 0.8652 - recall: 0.8707\n",
            "Epoch 582/600\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.3024 - accuracy: 0.8625 - precision: 0.8676 - recall: 0.8555\n",
            "Epoch 583/600\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3085 - accuracy: 0.8644 - precision: 0.8621 - recall: 0.8675\n",
            "Epoch 584/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3033 - accuracy: 0.8631 - precision: 0.8595 - recall: 0.8681\n",
            "Epoch 585/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3082 - accuracy: 0.8597 - precision: 0.8580 - recall: 0.8618\n",
            "Epoch 586/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.2951 - accuracy: 0.8698 - precision: 0.8676 - recall: 0.8726\n",
            "Epoch 587/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3040 - accuracy: 0.8660 - precision: 0.8699 - recall: 0.8606\n",
            "Epoch 588/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3029 - accuracy: 0.8704 - precision: 0.8734 - recall: 0.8662\n",
            "Epoch 589/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3082 - accuracy: 0.8603 - precision: 0.8614 - recall: 0.8587\n",
            "Epoch 590/600\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.3066 - accuracy: 0.8638 - precision: 0.8614 - recall: 0.8669\n",
            "Epoch 591/600\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.2981 - accuracy: 0.8691 - precision: 0.8675 - recall: 0.8713\n",
            "Epoch 592/600\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2981 - accuracy: 0.8666 - precision: 0.8668 - recall: 0.8662\n",
            "Epoch 593/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3044 - accuracy: 0.8675 - precision: 0.8666 - recall: 0.8688\n",
            "Epoch 594/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3159 - accuracy: 0.8556 - precision: 0.8560 - recall: 0.8549\n",
            "Epoch 595/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3229 - accuracy: 0.8590 - precision: 0.8592 - recall: 0.8587\n",
            "Epoch 596/600\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 0.3108 - accuracy: 0.8612 - precision: 0.8589 - recall: 0.8644\n",
            "Epoch 597/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3012 - accuracy: 0.8616 - precision: 0.8627 - recall: 0.8599\n",
            "Epoch 598/600\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.3112 - accuracy: 0.8669 - precision: 0.8669 - recall: 0.8669\n",
            "Epoch 599/600\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3136 - accuracy: 0.8571 - precision: 0.8569 - recall: 0.8574\n",
            "Epoch 600/600\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3066 - accuracy: 0.8650 - precision: 0.8659 - recall: 0.8637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b624d349ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rtVAbC5Gzrz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b381ec-9f4c-40a8-94ca-68979f0230ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 4s 123ms/step - loss: 0.6549 - accuracy: 0.7285 - precision: 0.6618 - recall: 0.9357\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6548835039138794,\n",
              " 0.7284768223762512,\n",
              " 0.6617646813392639,\n",
              " 0.9357277750968933]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HGfnRfsdvEH"
      },
      "source": [
        "## 5.2. Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qzgvx_RydrLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f538fe-4f86-4a51-d815-01e08b075567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 4s 124ms/step\n"
          ]
        }
      ],
      "source": [
        "y_predict = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ykN19eBifFdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec159877-7e8e-46de-c980-1bfa9d5c9527"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.952277  , 0.16021143, 0.07557397, ..., 0.7060959 , 0.4455591 ,\n",
              "       0.40928704], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "y_predict = y_predict.flatten()\n",
        "y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Yae_7cvJfhk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855a929c-b91e-4957-fca7-192fdb1c5e1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_predict = np.where(y_predict > 0.5, 1, 0)\n",
        "y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8af_GT6pgEx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "27dde353-4ef2-41fa-8550-9d22157e1122"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cmtrix = confusion_matrix(y_test, y_predict)\n",
        "sns.heatmap(cmtrix, annot=True, fmt='d')\n",
        "\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Truth\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HEaJyz3JhnT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5353da93-ea41-42d5-b620-b8862dbf9f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.52      0.66       528\n",
            "           1       0.66      0.94      0.78       529\n",
            "\n",
            "    accuracy                           0.73      1057\n",
            "   macro avg       0.78      0.73      0.72      1057\n",
            "weighted avg       0.78      0.73      0.72      1057\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_predict))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}